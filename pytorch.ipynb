{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUSMAbyJhHNTthBazCZSUx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Pytorch/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ipdb"
      ],
      "metadata": {
        "id": "OeB0VUJSkekh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "tensor_size = (10000, 10000)\n",
        "a = torch.randn(tensor_size, device=device)\n",
        "b = torch.randn(tensor_size, device=device)\n",
        "# ipdb.set_trace()\n",
        "\n",
        "c = a + b\n",
        "# ipdb.set_trace()\n",
        "\n",
        "print(\"Result shape (moved to CPU for printing):\", c.cpu().shape)\n",
        "\n",
        "print(\"Current GPU memory usage:\")\n",
        "print(f\"Allocated: {torch.cuda.memory_allocated(device) / (1024 ** 2):.2f} MB\")\n",
        "print(f\"Cached: {torch.cuda.memory_reserved(device) / (1024 ** 2):.2f} MB\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 4)\n",
        "        self.fc2 = nn.Linear(4, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "X_train = torch.tensor([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
        "y_train = torch.tensor([[0.0], [1.0], [1.0], [0.0]])\n",
        "\n",
        "import torch.optim as optim\n",
        "model = SimpleNN()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # ipdb.set_trace()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        # ipdb.set_trace()\n",
        "        print(f'Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_data = torch.tensor([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
        "    predictions = model(test_data)\n",
        "    print(f'Predictions:\\n{predictions}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBSy5iQML_PN",
        "outputId": "43d3554f-7b27-4f32-fb22-6975a53591b3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Result shape (moved to CPU for printing): torch.Size([10000, 10000])\n",
            "Current GPU memory usage:\n",
            "Allocated: 0.00 MB\n",
            "Cached: 0.00 MB\n",
            "Epoch [10/100], Loss: 0.2796\n",
            "Epoch [20/100], Loss: 0.2587\n",
            "Epoch [30/100], Loss: 0.2434\n",
            "Epoch [40/100], Loss: 0.2263\n",
            "Epoch [50/100], Loss: 0.2084\n",
            "Epoch [60/100], Loss: 0.1908\n",
            "Epoch [70/100], Loss: 0.1737\n",
            "Epoch [80/100], Loss: 0.1579\n",
            "Epoch [90/100], Loss: 0.1461\n",
            "Epoch [100/100], Loss: 0.1347\n",
            "Predictions:\n",
            "tensor([[0.2952],\n",
            "        [0.8278],\n",
            "        [0.4926],\n",
            "        [0.4033]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "        self.labels = torch.tensor([0, 1, 0])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # ipdb.set_trace()\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "dataset = MyDataset()\n",
        "# ipdb.set_trace()\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "for batch in dataloader:\n",
        "    # ipdb.set_trace()\n",
        "    print(\"Batch Data:\", batch[0])  #Manual: dataset[0] or dataset.__getitem__(0)Automatic: When you iterate over a DataLoader, it calls __getitem__() for each index in the batch.\n",
        "    print(\"Batch Labels:\", batch[1])\n",
        "\n",
        "for epoch in range(2):\n",
        "    for inputs, labels in dataloader:\n",
        "\n",
        "        outputs = inputs + 1\n",
        "        print(f\"Epoch {epoch + 1}, Inputs: {inputs}, Labels: {labels}, Outputs: {outputs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0T8t1Xjl38e",
        "outputId": "bff4d8f3-513b-4d97-8789-78196cb5d97c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Data: tensor([[5., 6.],\n",
            "        [3., 4.]])\n",
            "Batch Labels: tensor([0, 1])\n",
            "Batch Data: tensor([[1., 2.]])\n",
            "Batch Labels: tensor([0])\n",
            "Epoch 1, Inputs: tensor([[5., 6.],\n",
            "        [1., 2.]]), Labels: tensor([0, 0]), Outputs: tensor([[6., 7.],\n",
            "        [2., 3.]])\n",
            "Epoch 1, Inputs: tensor([[3., 4.]]), Labels: tensor([1]), Outputs: tensor([[4., 5.]])\n",
            "Epoch 2, Inputs: tensor([[1., 2.],\n",
            "        [5., 6.]]), Labels: tensor([0, 0]), Outputs: tensor([[2., 3.],\n",
            "        [6., 7.]])\n",
            "Epoch 2, Inputs: tensor([[3., 4.]]), Labels: tensor([1]), Outputs: tensor([[4., 5.]])\n"
          ]
        }
      ]
    }
  ]
}